{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question & Answering Using LangChain\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Loading packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain import FAISS, OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Reading OpenAI API Key from .env file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file\n",
    "cwd = os.getcwd()\n",
    "dotenv_filepath = os.path.join(cwd, \"../../.env\")\n",
    "load_dotenv(dotenv_filepath)\n",
    "\n",
    "# Create a connection string that includes your Azure SQL Server details,\n",
    "# such as the server name, database name, username, and password.\n",
    "OPEN_AI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Defining function to create and load embeddings from external documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsService:\n",
    "    CURRENT_DIRECTORY = \".\"\n",
    "    FILE_PATH_ASSETS = \"../../data/qna_doc_retrieval\"\n",
    "    EMBEDDINGS_PATH = FILE_PATH_ASSETS + \"/embeddings\"\n",
    "\n",
    "    def get_embedded_file_path(document_name):\n",
    "        return (\n",
    "            EmbeddingsService.EMBEDDINGS_PATH + \"/\" + document_name + \".embedding.pkl\"\n",
    "        )\n",
    "\n",
    "    def get_raw_file_path(document_name):\n",
    "        return EmbeddingsService.FILE_PATH_ASSETS + \"/raw/\" + document_name\n",
    "\n",
    "    @staticmethod\n",
    "    def create_embeddings(file_name):\n",
    "        if file_name == \"ALL\":\n",
    "            # iterate over all files in app/assets/raw, and create embeddings for each\n",
    "            for file in os.listdir(EmbeddingsService.FILE_PATH_ASSETS + \"/raw\"):\n",
    "                EmbeddingsService.create_embeddings_for_file(file)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_embeddings_for_file(file_name):\n",
    "        # check if embedding file already exists.  It would exist in the folder app/assets/embeddings with filename +\n",
    "        # .embedding.pkl.  If it exists, then skip it.  If it does not exist, then create it.\n",
    "        embedded_file_path = EmbeddingsService.get_embedded_file_path(file_name)\n",
    "        if os.path.exists(embedded_file_path):\n",
    "            print(\"Embeddings file already exists.  Skipping...\" + embedded_file_path)\n",
    "            return\n",
    "        else:\n",
    "            raw_file_path = EmbeddingsService.get_raw_file_path(file_name)\n",
    "            print(\n",
    "                \"Creating embeddings for file: \"\n",
    "                + raw_file_path\n",
    "                + \" and saving to: \"\n",
    "                + embedded_file_path\n",
    "            )\n",
    "            EmbeddingsService.create_embeddings_and_save(\n",
    "                raw_file_path, embedded_file_path\n",
    "            )\n",
    "            print(\"Embeddings created successfully for: \" + embedded_file_path)\n",
    "            return\n",
    "\n",
    "    @staticmethod\n",
    "    def create_embeddings_and_save(raw_file_path, embedded_file_path):\n",
    "        print(\"Creating embeddings...\")\n",
    "        with open(raw_file_path) as f:\n",
    "            file_to_split = f.read()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "        texts = text_splitter.split_text(file_to_split)\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "\n",
    "        # Vector store.  Object which stores the embeddings and allows for fast retrieval.\n",
    "        docsearch = FAISS.from_texts(\n",
    "            texts, embeddings, metadatas=[{\"source\": i} for i in range(len(texts))]\n",
    "        )\n",
    "\n",
    "        v = [docsearch, texts]\n",
    "\n",
    "        # save to pickle\n",
    "        with open(embedded_file_path, \"wb\") as f:\n",
    "            pickle.dump(v, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_embeddings(document_name):\n",
    "        embedded_file_path = EmbeddingsService.get_embedded_file_path(document_name)\n",
    "        if os.path.exists(embedded_file_path):\n",
    "            print(\"Loading embeddings from file...\")\n",
    "            with open(embedded_file_path, \"rb\") as f:\n",
    "                docsearch, texts = pickle.load(f)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Embeddings file does not exist.  Please create embeddings file first.\"\n",
    "            )\n",
    "        return {\"docsearch\": docsearch, \"texts\": texts}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Defining function to find similar embeddings from documents based on query (question) and returning answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerRetriever:\n",
    "    def get_answer(self, embeddings, query):\n",
    "        texts = embeddings[\"texts\"]\n",
    "        docsearch = embeddings[\"docsearch\"]\n",
    "        docs = docsearch.similarity_search(query)\n",
    "        chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "        answer = chain(\n",
    "            {\"input_documents\": docs, \"question\": query}, return_only_outputs=True\n",
    "        )\n",
    "        sources_indexes = re.findall(r\"\\d+\", answer[\"output_text\"].splitlines()[-1])\n",
    "        sources_indexes = [int(i) for i in sources_indexes]\n",
    "        sources_list = []\n",
    "        for idx in sources_indexes:\n",
    "            sources_list.append(texts[idx])\n",
    "\n",
    "        # remove sources from answer\n",
    "        answer_str = answer[\"output_text\"].split(\"\\nSOURCES:\")[0]\n",
    "\n",
    "        response = {\"answer\": answer_str, \"sources\": sources_list}\n",
    "\n",
    "        # code to load embeddings\n",
    "        return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Create embeddings from documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings file already exists.  Skipping...../../data/qna_doc_retrieval/embeddings/nvidia_q4_2023_earnings_call_transcript.txt.embedding.pkl\n",
      "Embeddings file already exists.  Skipping...../../data/qna_doc_retrieval/embeddings/tsla_earnings_transcript_q4_2022.txt.embedding.pkl\n"
     ]
    }
   ],
   "source": [
    "EmbeddingsService.create_embeddings(\"ALL\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Load embeddings from documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from file...\n"
     ]
    }
   ],
   "source": [
    "document = \"tsla_earnings_transcript_q4_2022.txt\"\n",
    "embeddings = EmbeddingsService.load_embeddings(document)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Question & Answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  The main points from the call include customer interest in Tesla's products remaining high, plans to rapidly increase volume while improving overhead efficiency, and the need to redesign the supply chain to make it more efficient.  \n",
      "\n",
      "---------- \n",
      "\n",
      "Sources from document:  \n",
      "\n",
      "Source 0:\n",
      "These improvements include our continued work to gradually move toward a regionally balanced build of vehicles. The energy business had its strongest year yet across all metrics, led by steady improvement in both retail and commercial storage. While much work remains to grow this business and improve costs, we believe we are on a good trajectory. As we look toward 2023, we are moving forward aggressively leveraging our strength and cost.\n",
      "\n",
      "There are three key points I wanted to make here. First, on demand, as Elon mentioned, customer interest in our products remains high. Second, on cost reduction, we're holding steady on our plans to rapidly increase volume while improving overhead efficiency, which is the most effective method to retain strength in our operating margins. In particular, we're accelerating improvements in our new factories in Austin, Berlin and in-house cells, where inefficiencies are the highest. \n",
      "\n",
      "Source 1:\n",
      "We're looking forward to discussing these plans in more detail on our investor day in a month. Thank you.\n",
      "\n",
      "Martin Viecha\n",
      "\n",
      "Thank you very much, Zach. Let's now go to investor questions. The first question is, some analysts are claiming that Tesla orders, net of cancellations, came in at a rate less than half of production in the fourth quarter. This has raised demand concerns.\n",
      "\n",
      "Can you elaborate on order trends so far this year and how they compare to current production rates? I think --\n",
      "\n",
      "Elon Musk -- Chief Executive Officer and Product Architect\n",
      "\n",
      "We already answered that question.\n",
      "\n",
      "Martin Viecha\n",
      "\n",
      "Yes, exactly.\n",
      "\n",
      "Elon Musk -- Chief Executive Officer and Product Architect\n",
      "\n",
      "Demand far exceeds production, and we actually are making some small price increases as a result.\n",
      "\n",
      "Martin Viecha \n",
      "\n",
      "Source 2:\n",
      "Yes. Like on the non-cells raw material, we begin to capture benefits of indexes tapering out, but due to the length of various supply chains, it does take time before this is reflected in our financials. And while aluminum is down like 20% year over year, steel is about 30% down year over year, the global non-cells raw materials market continues to be influenced by geopolitical situations in Europe, high production cost due to labor cost increases and energy spikes and disruptions due to natural disasters like typhoon in Korea four months ago, pandemic lockdowns. So we believe that meaningful price corrections will ultimately come, but it remains uncertain exactly when.\n",
      "\n",
      "In the meantime, we continue to redesign supply chain to make it more efficient and work with our supplier partners to find more efficiencies, streamline logistics and transportation to produce cars.\n",
      "\n",
      "Martin Viecha\n",
      "\n",
      "Sorry, do you want to go say something? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"what are the main points from the call?\"\n",
    "results = AnswerRetriever().get_answer(embeddings, query)\n",
    "\n",
    "print(\"AI: {}\".format(results[\"answer\"]), \"\\n\")\n",
    "print(\"----------\", \"\\n\")\n",
    "print(\"Sources from document: \", \"\\n\")\n",
    "for i, source in enumerate(results[\"sources\"]):\n",
    "    print(\"Source {}:\".format(i))\n",
    "    print(source, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  In Q4 2022, Tesla reported revenue increased over 50%, operating income doubled, free cash flows increased over 50%, and their margins remained industry-leading. Additionally, non-GAAP opex as a percentage of revenue improved further. \n",
      "\n",
      "---------- \n",
      "\n",
      "Sources from document:  \n",
      "\n",
      "Source 0:\n",
      "Tesla (TSLA 10.97%)\n",
      "Q4 2022 Earnings Call\n",
      "Jan 25, 2023, 5:30 p.m. ET\n",
      "\n",
      "Contents:\n",
      "Prepared Remarks\n",
      "Questions and Answers\n",
      "Call Participants\n",
      "Prepared Remarks:\n",
      "\n",
      "Martin Viecha\n",
      "\n",
      "Good afternoon, everyone, and welcome to Tesla's fourth quarter 2022 Q&A webcast. My name is Martin Viecha, VP of investor relations, and I'm joined today by Elon Musk, Zachary Kirkhorn and a number of other executives. Our Q4 results were announced at about 3:00 p.m. Central Time in the update deck we published at the same link as this webcast.\n",
      "\n",
      "During this call, we will discuss our business outlook and make forward-looking statements. These comments are based on our predictions and expectations as of today. Actual events or results could differ materially due to a number of risks and uncertainties, including those mentioned in our most recent filings with the SEC. [Operator instructions] But before we jump into Q&A, Elon has some opening remarks.\n",
      "\n",
      "Find out why Tesla is one of the 10 best stocks to buy now \n",
      "\n",
      "Source 1:\n",
      "We're looking forward to discussing these plans in more detail on our investor day in a month. Thank you.\n",
      "\n",
      "Martin Viecha\n",
      "\n",
      "Thank you very much, Zach. Let's now go to investor questions. The first question is, some analysts are claiming that Tesla orders, net of cancellations, came in at a rate less than half of production in the fourth quarter. This has raised demand concerns.\n",
      "\n",
      "Can you elaborate on order trends so far this year and how they compare to current production rates? I think --\n",
      "\n",
      "Elon Musk -- Chief Executive Officer and Product Architect\n",
      "\n",
      "We already answered that question.\n",
      "\n",
      "Martin Viecha\n",
      "\n",
      "Yes, exactly.\n",
      "\n",
      "Elon Musk -- Chief Executive Officer and Product Architect\n",
      "\n",
      "Demand far exceeds production, and we actually are making some small price increases as a result.\n",
      "\n",
      "Martin Viecha \n",
      "\n",
      "Source 2:\n",
      "Martin Viecha\n",
      "\n",
      "Thanks, Elon. And I think Zach has some opening remarks as well.\n",
      "\n",
      "Zach Kirkhorn -- Chief Financial Officer\n",
      "\n",
      "Yes. Thanks, Martin. So as Elon mentioned, 2022 was a terrific year for Tesla. I also want to congratulate the Tesla team and also say thank you to our suppliers for your support during quite a volatile year.\n",
      "\n",
      "On a full year basis, revenue increased over 50%, operating income doubled, free cash flows increased over 50%, and our margins remained industry-leading. Additionally, we continued to make progress on overhead efficiencies as non-GAAP opex as a percentage of revenue improved further. For Q4 specifically, sequential and annual margin was impacted by ASP reductions as we are managing through COVID impacts in China, uncertainty around the consumer tax credit in the U.S. and a rising interest rate environment. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"Pls summarize or extract out the numbers from the earning call report\"\n",
    "results2 = AnswerRetriever().get_answer(embeddings, query2)\n",
    "\n",
    "print(\"AI: {}\".format(results2[\"answer\"]), \"\\n\")\n",
    "print(\"----------\", \"\\n\")\n",
    "print(\"Sources from document: \", \"\\n\")\n",
    "for i, source in enumerate(results2[\"sources\"]):\n",
    "    print(\"Source {}:\".format(i))\n",
    "    print(source, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docqueryenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
