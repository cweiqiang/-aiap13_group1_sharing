{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from decouple import config, AutoConfig\n",
    "\n",
    "from langchain import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "# from app.config.config import OPEN_AI_API_KEY\n",
    "\n",
    "config = AutoConfig(search_path='.env')\n",
    "\n",
    "OPEN_AI_API_KEY = config('OPEN_AI_API_KEY')\n",
    "\n",
    "class EmbeddingsService:\n",
    "    # CURRENT_DIRECTORY = os.path.dirname(__file__)\n",
    "    # FILE_PATH_ASSETS = os.path.join(CURRENT_DIRECTORY, \"../assets\")\n",
    "    # EMBEDDINGS_PATH = FILE_PATH_ASSETS + '/embeddings/'\n",
    "\n",
    "    CURRENT_DIRECTORY = '.'\n",
    "    FILE_PATH_ASSETS = './assets'\n",
    "    EMBEDDINGS_PATH = FILE_PATH_ASSETS + '/embeddings'\n",
    "\n",
    "    def get_embedded_file_path(document_name):\n",
    "        return EmbeddingsService.EMBEDDINGS_PATH + '/' + document_name + '.embedding.pkl'\n",
    "\n",
    "    def get_raw_file_path(document_name):\n",
    "        return EmbeddingsService.FILE_PATH_ASSETS + '/raw/' + document_name\n",
    "\n",
    "    @staticmethod\n",
    "    def create_embeddings(file_name):\n",
    "        if file_name == 'ALL':\n",
    "            # iterate over all files in app/assets/raw, and create embeddings for each\n",
    "            for file in os.listdir(EmbeddingsService.FILE_PATH_ASSETS + '/raw'):\n",
    "                EmbeddingsService.create_embeddings_for_file(file)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_embeddings_for_file(file_name):\n",
    "        # check if embedding file already exists.  It would exist in the folder app/assets/embeddings with filename +\n",
    "        # .embedding.pkl.  If it exists, then skip it.  If it does not exist, then create it.\n",
    "        embedded_file_path = EmbeddingsService.get_embedded_file_path(file_name)\n",
    "        if os.path.exists(embedded_file_path):\n",
    "            print('Embeddings file already exists.  Skipping...' + embedded_file_path)\n",
    "            return\n",
    "        else:\n",
    "            raw_file_path = EmbeddingsService.get_raw_file_path(file_name)\n",
    "            print('Creating embeddings for file: ' + raw_file_path + ' and saving to: ' + embedded_file_path)\n",
    "            EmbeddingsService.create_embeddings_and_save(raw_file_path, embedded_file_path)\n",
    "            print('Embeddings created successfully for: ' + embedded_file_path)\n",
    "            return\n",
    "\n",
    "    @staticmethod\n",
    "    def create_embeddings_and_save(raw_file_path, embedded_file_path):\n",
    "        print('Creating embeddings...')\n",
    "        os.environ[\"OPENAI_API_KEY\"] = OPEN_AI_API_KEY\n",
    "        with open(raw_file_path) as f:\n",
    "            file_to_split = f.read()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "        texts = text_splitter.split_text(file_to_split)\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        # embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "        # Vector store.  Object which stores the embeddings and allows for fast retrieval.\n",
    "        docsearch = FAISS.from_texts(texts, embeddings, metadatas=[{\"source\": i} for i in range(len(texts))])\n",
    "\n",
    "        v = [docsearch, texts]\n",
    "\n",
    "        # save to pickle\n",
    "        with open(embedded_file_path, 'wb') as f:\n",
    "            pickle.dump(v, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_embeddings(document_name):\n",
    "        os.environ[\"OPENAI_API_KEY\"] = OPEN_AI_API_KEY\n",
    "        embedded_file_path = EmbeddingsService.get_embedded_file_path(document_name)\n",
    "        if os.path.exists(embedded_file_path):\n",
    "            print('Loading embeddings from file...')\n",
    "            with open(embedded_file_path, 'rb') as f:\n",
    "                docsearch, texts = pickle.load(f)\n",
    "        else:\n",
    "            raise Exception('Embeddings file does not exist.  Please create embeddings file first.')\n",
    "        return {'docsearch': docsearch, 'texts': texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "\n",
    "class AnswerRetriever:\n",
    "    def get_answer(self, embeddings, query):\n",
    "        texts = embeddings['texts']\n",
    "        docsearch = embeddings['docsearch']\n",
    "        docs = docsearch.similarity_search(query)\n",
    "        chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "        answer = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
    "        sources_indexes = re.findall(r'\\d+', answer['output_text'].splitlines()[-1])\n",
    "        sources_indexes = [int(i) for i in sources_indexes]\n",
    "        sources_list = []\n",
    "        for idx in sources_indexes:\n",
    "            sources_list.append(texts[idx])\n",
    "\n",
    "        # remove sources from answer\n",
    "        answer_str = answer['output_text'].split(\"\\nSOURCES:\")[0]\n",
    "\n",
    "        response = {\n",
    "            'answer': answer_str,\n",
    "            'sources': sources_list\n",
    "        }\n",
    "\n",
    "        # code to load embeddings\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for file: ./assets/raw/tsla_earnings_transcript_q4_2022.txt and saving to: ./assets/embeddings/tsla_earnings_transcript_q4_2022.txt.embedding.pkl\n",
      "Creating embeddings...\n",
      "Embeddings created successfully for: ./assets/embeddings/tsla_earnings_transcript_q4_2022.txt.embedding.pkl\n"
     ]
    }
   ],
   "source": [
    "EmbeddingsService.create_embeddings(\"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from file...\n"
     ]
    }
   ],
   "source": [
    "document = 'tsla_earnings_transcript_q4_2022.txt'\n",
    "embeddings = EmbeddingsService.load_embeddings(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what are the main points from the call?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = AnswerRetriever().get_answer(embeddings, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': \" The main points from the call include customer interest in Tesla's products remaining high, plans to rapidly increase volume while improving overhead efficiency, and the need to redesign the supply chain to make it more efficient. \",\n",
       " 'sources': [\"These improvements include our continued work to gradually move toward a regionally balanced build of vehicles. The energy business had its strongest year yet across all metrics, led by steady improvement in both retail and commercial storage. While much work remains to grow this business and improve costs, we believe we are on a good trajectory. As we look toward 2023, we are moving forward aggressively leveraging our strength and cost.\\n\\nThere are three key points I wanted to make here. First, on demand, as Elon mentioned, customer interest in our products remains high. Second, on cost reduction, we're holding steady on our plans to rapidly increase volume while improving overhead efficiency, which is the most effective method to retain strength in our operating margins. In particular, we're accelerating improvements in our new factories in Austin, Berlin and in-house cells, where inefficiencies are the highest.\",\n",
       "  \"We're looking forward to discussing these plans in more detail on our investor day in a month. Thank you.\\n\\nMartin Viecha\\n\\nThank you very much, Zach. Let's now go to investor questions. The first question is, some analysts are claiming that Tesla orders, net of cancellations, came in at a rate less than half of production in the fourth quarter. This has raised demand concerns.\\n\\nCan you elaborate on order trends so far this year and how they compare to current production rates? I think --\\n\\nElon Musk -- Chief Executive Officer and Product Architect\\n\\nWe already answered that question.\\n\\nMartin Viecha\\n\\nYes, exactly.\\n\\nElon Musk -- Chief Executive Officer and Product Architect\\n\\nDemand far exceeds production, and we actually are making some small price increases as a result.\\n\\nMartin Viecha\",\n",
       "  'Yes. Like on the non-cells raw material, we begin to capture benefits of indexes tapering out, but due to the length of various supply chains, it does take time before this is reflected in our financials. And while aluminum is down like 20% year over year, steel is about 30% down year over year, the global non-cells raw materials market continues to be influenced by geopolitical situations in Europe, high production cost due to labor cost increases and energy spikes and disruptions due to natural disasters like typhoon in Korea four months ago, pandemic lockdowns. So we believe that meaningful price corrections will ultimately come, but it remains uncertain exactly when.\\n\\nIn the meantime, we continue to redesign supply chain to make it more efficient and work with our supplier partners to find more efficiencies, streamline logistics and transportation to produce cars.\\n\\nMartin Viecha\\n\\nSorry, do you want to go say something?']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docqueryenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
